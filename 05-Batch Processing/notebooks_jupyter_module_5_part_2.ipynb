{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e009048",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5dfa9007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.1.3\n"
     ]
    }
   ],
   "source": [
    "print(spark.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7bf22b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spark session\n",
    "spark = SparkSession.builder \\\n",
    "  .master('yarn') \\\n",
    "  .appName('module 5_1') \\\n",
    "  .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37af9bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = \"gs://data-zoom-bucket/yellow_tripdata_2024-10.parquet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "919fface",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    " df = spark.read.parquet(input_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2f88463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- VendorID: integer (nullable = true)\n",
      " |-- tpep_pickup_datetime: timestamp (nullable = true)\n",
      " |-- tpep_dropoff_datetime: timestamp (nullable = true)\n",
      " |-- passenger_count: long (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- RatecodeID: long (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- PULocationID: integer (nullable = true)\n",
      " |-- DOLocationID: integer (nullable = true)\n",
      " |-- payment_type: long (nullable = true)\n",
      " |-- fare_amount: double (nullable = true)\n",
      " |-- extra: double (nullable = true)\n",
      " |-- mta_tax: double (nullable = true)\n",
      " |-- tip_amount: double (nullable = true)\n",
      " |-- tolls_amount: double (nullable = true)\n",
      " |-- improvement_surcharge: double (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      " |-- congestion_surcharge: double (nullable = true)\n",
      " |-- Airport_fee: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a97cbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"taxi_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e197db1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 5:=============================>                             (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|record_count|\n",
      "+------------+\n",
      "|      128893|\n",
      "+------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "result = spark.sql(\"\"\"\n",
    "    SELECT COUNT(*) AS record_count\n",
    "    FROM taxi_data\n",
    "    WHERE DATE(tpep_pickup_datetime) = '2024-10-15' \n",
    "\"\"\")\n",
    "\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa975f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f3f8bcb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "128893"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df \\\n",
    "    .withColumn('pickup_date', F.to_date(df.tpep_pickup_datetime)) \\\n",
    "    .filter(\"pickup_date = '2024-10-15'\") \\\n",
    "    .count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8ddb3b9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 18:=============================>                            (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------------+\n",
      "|pickup_date|          duration|\n",
      "+-----------+------------------+\n",
      "| 2024-10-16|162.61777777777777|\n",
      "| 2024-10-03|           143.325|\n",
      "| 2024-10-22|137.76055555555556|\n",
      "| 2024-10-18|114.83472222222223|\n",
      "| 2024-10-21| 89.89833333333333|\n",
      "| 2024-10-20| 89.44611111111111|\n",
      "| 2024-10-12| 67.57333333333334|\n",
      "| 2024-10-17| 66.06666666666666|\n",
      "| 2024-10-24| 38.47416666666667|\n",
      "| 2024-10-23| 33.95111111111111|\n",
      "+-----------+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT\n",
    "    to_date(tpep_pickup_datetime) AS pickup_date,\n",
    "    MAX((CAST(tpep_dropoff_datetime AS LONG) - CAST(tpep_pickup_datetime AS LONG)) / (60*60)) AS duration\n",
    "FROM \n",
    "    taxi_data\n",
    "GROUP BY\n",
    "    1\n",
    "ORDER BY\n",
    "    2 DESC\n",
    "LIMIT 10;\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5920cdc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path2 = \"gs://data-zoom-bucket/taxi_zone_lookup.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e3187979",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_loopup = spark.read.csv(input_path2, header=True, inferSchema=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e4435caf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- LocationID: integer (nullable = true)\n",
      " |-- Borough: string (nullable = true)\n",
      " |-- Zone: string (nullable = true)\n",
      " |-- service_zone: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_loopup.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "93a3da50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+--------------------+------------+\n",
      "|LocationID|      Borough|                Zone|service_zone|\n",
      "+----------+-------------+--------------------+------------+\n",
      "|         1|          EWR|      Newark Airport|         EWR|\n",
      "|         2|       Queens|         Jamaica Bay|   Boro Zone|\n",
      "|         3|        Bronx|Allerton/Pelham G...|   Boro Zone|\n",
      "|         4|    Manhattan|       Alphabet City| Yellow Zone|\n",
      "|         5|Staten Island|       Arden Heights|   Boro Zone|\n",
      "|         6|Staten Island|Arrochar/Fort Wad...|   Boro Zone|\n",
      "|         7|       Queens|             Astoria|   Boro Zone|\n",
      "|         8|       Queens|        Astoria Park|   Boro Zone|\n",
      "|         9|       Queens|          Auburndale|   Boro Zone|\n",
      "|        10|       Queens|        Baisley Park|   Boro Zone|\n",
      "|        11|     Brooklyn|          Bath Beach|   Boro Zone|\n",
      "|        12|    Manhattan|        Battery Park| Yellow Zone|\n",
      "|        13|    Manhattan|   Battery Park City| Yellow Zone|\n",
      "|        14|     Brooklyn|           Bay Ridge|   Boro Zone|\n",
      "|        15|       Queens|Bay Terrace/Fort ...|   Boro Zone|\n",
      "|        16|       Queens|             Bayside|   Boro Zone|\n",
      "|        17|     Brooklyn|             Bedford|   Boro Zone|\n",
      "|        18|        Bronx|        Bedford Park|   Boro Zone|\n",
      "|        19|       Queens|           Bellerose|   Boro Zone|\n",
      "|        20|        Bronx|             Belmont|   Boro Zone|\n",
      "+----------+-------------+--------------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_loopup.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c709c599",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loopup.createOrReplaceTempView(\"zone_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "668fe815",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 33:=============================>                            (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------------+---------+\n",
      "|PULocationID|                Zone|rec_count|\n",
      "+------------+--------------------+---------+\n",
      "|         105|Governor's Island...|        1|\n",
      "|           5|       Arden Heights|        2|\n",
      "|         199|       Rikers Island|        2|\n",
      "|           2|         Jamaica Bay|        3|\n",
      "|         111| Green-Wood Cemetery|        3|\n",
      "|         204|   Rossville/Woodrow|        4|\n",
      "|         245|       West Brighton|        4|\n",
      "|          84|Eltingville/Annad...|        4|\n",
      "|          44|Charleston/Totten...|        4|\n",
      "|         187|       Port Richmond|        4|\n",
      "+------------+--------------------+---------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT\n",
    "    a.PULocationID,\n",
    "    b.Zone,\n",
    "    count(1) rec_count\n",
    "FROM \n",
    "    taxi_data a\n",
    "    left join zone_table b on a.PULocationID = b.LocationID\n",
    "GROUP BY\n",
    "    1,2\n",
    "ORDER BY\n",
    "    3\n",
    "LIMIT 10;\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "42e01803",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repartition data (adjust the number as needed)\n",
    "repartitioned_df = df.repartition(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ec57bbce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "output_path = \"gs://zoom-batch-storage/output/module5\"\n",
    "repartitioned_df.write \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .parquet(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f6af069a",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}